{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check and run `transplants_investigation.ipynb` before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from typing import List\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "from local_testing_utilities.notebook_utils.pairing_data import parse_pairing_data\n",
    "from local_testing_utilities.notebook_utils.survival_data import parse_survival_data\n",
    "from txmatching.utils.blood_groups import BloodGroup\n",
    "from txmatching.utils.country_enum import Country\n",
    "from txmatching.patients.patient import Donor, Recipient\n",
    "from txmatching.patients.patient_parameters import PatientParameters\n",
    "from tests.test_utilities.hla_preparation_utils import (create_antibodies, create_antibody,\n",
    "                                                        create_hla_typing)\n",
    "from tests.test_utilities.prepare_app_for_tests import DbTests\n",
    "from txmatching.patients.patient import TxmEvent\n",
    "from txmatching.utils.enums import TxmEventState\n",
    "from txmatching.configuration.configuration import Configuration\n",
    "from txmatching.solve_service.solve_from_configuration import solve_from_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_patients = parse_pairing_data('data/KDP-processed', 'data/patients_list_recipientID.csv', remove_single_donors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survival = parse_survival_data('data/LD_kidney_survival.csv')\n",
    "df_survival_summary = pd.read_pickle('data/survival_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients_with_recipient_id = pd.read_csv('data/patients_list_recipientID.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’â€â™‚ï¸ Run solver on data with various granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the patients in old txm events and join survival data to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_survival_summary = pd.read_pickle('data/survival_summary.pkl')\n",
    "df_survival_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transplanted_donors = pd.read_excel('data/transplanted_donors.xlsx', index_col=None)\n",
    "df_transplanted_donors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donors_last_event_with_surv = df_donors_last_event\\\n",
    "    .join(df_transplanted_donors.set_index('donor_name')['target_recipient_id'], on='donor_name')\\\n",
    "    .join(df_survival_summary.set_index('RecipientID'), on='target_recipient_id', rsuffix='_surv')\n",
    "#df_donors_last_event_with_surv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_patients\\\n",
    "    .join(df_transplanted_donors.set_index('donor_name')['target_recipient_id'], on='donor_name')\\\n",
    "    .join(df_survival_summary.set_index('RecipientID').add_suffix('_donor_surv'), on='target_recipient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_patients_with_survival = df_all_patients\\\n",
    "    .join(df_survival_summary.set_index('RecipientID').add_suffix('_recip_surv'), on='recipient_id')\\\n",
    "    .join(df_transplanted_donors.set_index('donor_name')['target_recipient_id'], on='donor_name')\\\n",
    "    .join(df_survival_summary.set_index('RecipientID').add_suffix('_donor_surv'), on='target_recipient_id')\\\n",
    "    .assign(recip_has_transplant=lambda df: df.delay_recip_surv.notnull())\\\n",
    "    .assign(donor_has_transplant=lambda df: df.delay_donor_surv.notnull())\n",
    "df_all_patients_with_survival\n",
    "\n",
    "# [lambda df: df.recipient_id.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_patients_with_survival[lambda df: df.donor_has_transplant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define function that returns patients that would be in txm event with different granularity.\n",
    "\n",
    "For given granularity, each event has patients from the originla event plus patients from $granularity - 1$ previous events that have been transplanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipients_for_granularity(txm_event, granularity):\n",
    "    df_patients_for_granularity = df_all_patients_with_survival.loc[\n",
    "        lambda df:\n",
    "        (df.txm_event == txm_event) | \n",
    "        ((df.txm_event > txm_event - granularity) & (df.txm_event < txm_event) & df.recip_has_transplant)\n",
    "    ]\n",
    "    df_patients_for_granularity = df_patients_for_granularity.drop_duplicates(subset=['recipient_id'], keep='last')#.reset_index()#.set_index('recipient_id')\n",
    "    df_patients_for_granularity = df_patients_for_granularity.loc[lambda df: df.recipient_id.notnull()]\n",
    "    return df_patients_for_granularity\n",
    "\n",
    "#get_recipients_for_granularity(txm_event=26, granularity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_donors_for_granularity(txm_event, granularity):\n",
    "    df_patients_for_granularity = df_all_patients_with_survival.loc[\n",
    "        lambda df:\n",
    "        (df.txm_event == txm_event) | \n",
    "        ((df.txm_event > txm_event - granularity) & (df.txm_event < txm_event) & df.donor_has_transplant)\n",
    "    ]\n",
    "    df_patients_for_granularity = df_patients_for_granularity.drop_duplicates(subset=['donor_name'], keep='last')#.reset_index()#.set_index('donor_name')\n",
    "    return df_patients_for_granularity\n",
    "\n",
    "#get_donors_for_granularity(txm_event=26, granularity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run the solver, we make some config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize db\n",
    "test = DbTests()\n",
    "test.setUp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.tearDown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel('WARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the solver. We define several functions for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_recipient(db_id, row):\n",
    "    recipient_typization = row.recipient_typization\n",
    "    recipient_antibodies = row.recipient_luminex_2\n",
    "    \n",
    "    recipient_blood_group = row.recipient_blood_group\n",
    "    recipient_acceptable_blood = row.recipient_acceptable_blood\n",
    "    \n",
    "    db_id = row.recipient_id\n",
    "    \n",
    "    if recipient_typization == '':\n",
    "        print(f\"Problem with recipient empty typization {db_id}\")\n",
    "        return None\n",
    "    \n",
    "    recipient_typing = recipient_typization.split(\" \")\n",
    "    recipient_antibodies = recipient_antibodies.split(\" \") if recipient_antibodies != '' else []\n",
    "    recipient_acceptable_blood = recipient_acceptable_blood.split(\" \") if recipient_acceptable_blood != '' else []\n",
    "    \n",
    "    recipient = Recipient(\n",
    "        db_id=db_id,\n",
    "        acceptable_blood_groups=[BloodGroup(group) for group in recipient_acceptable_blood],\n",
    "        related_donor_db_id=db_id,\n",
    "        medical_id=f'recipient_{db_id}',\n",
    "        parameters=PatientParameters(\n",
    "            blood_group=BloodGroup(recipient_blood_group),\n",
    "            country_code=Country.CZE,\n",
    "            hla_typing=create_hla_typing(recipient_typing)\n",
    "        ),\n",
    "        hla_antibodies=create_antibodies([create_antibody(raw_code, 2000, 2000) for raw_code in recipient_antibodies])\n",
    "    )\n",
    "    \n",
    "    return recipient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_donor(db_id, row):\n",
    "    donor_typization = row.donor_typization\n",
    "    donor_blood_group = row.donor_blood_group\n",
    "    donor_is_single = math.isnan(row.recipient_id)\n",
    "    \n",
    "    if not donor_is_single:\n",
    "        db_id = row.recipient_id\n",
    "    \n",
    "    if donor_typization == '':\n",
    "        print(f\"Problem with donor empty typization {db_id}\")\n",
    "        return None\n",
    "    \n",
    "    donor_typing = donor_typization.split(\" \")\n",
    "    \n",
    "    donor = Donor(\n",
    "        db_id=db_id,\n",
    "        medical_id=f'donor_{db_id}',\n",
    "        related_recipient_db_id=db_id if not donor_is_single else None,\n",
    "        parameters=PatientParameters(\n",
    "            blood_group=BloodGroup(donor_blood_group),\n",
    "            country_code=Country.CZE,\n",
    "            hla_typing=create_hla_typing(\n",
    "                donor_typing\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return donor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_for_patients(df_donors, df_recipients):\n",
    "    donors = []\n",
    "    recipients = []\n",
    "    \n",
    "    for index, row in df_donors.iterrows():\n",
    "        maybe_donor = row_to_donor(int(index), row)\n",
    "        if maybe_donor is None:\n",
    "            continue\n",
    "        \n",
    "        donors.append(maybe_donor)\n",
    "    \n",
    "    for index, row in df_recipients.iterrows():\n",
    "        maybe_recipient = row_to_recipient(int(index), row)\n",
    "        if maybe_recipient is None:\n",
    "            continue\n",
    "        \n",
    "        recipients.append(maybe_recipient)\n",
    "\n",
    "    txm_event = TxmEvent(1, 'sample_event', None, TxmEventState.OPEN, donors, recipients)\n",
    "    configuration = Configuration(\n",
    "        max_number_of_matchings=1,\n",
    "        max_cycle_length=10,\n",
    "        max_sequence_length=10,\n",
    "        # solver_constructor_name='AllSolutionsSolver'\n",
    "    )\n",
    "    pairing_result = solve_from_configuration(configuration, txm_event=txm_event)\n",
    "\n",
    "    matchings_count = len(pairing_result.calculated_matchings_list)\n",
    "    \n",
    "    if matchings_count > 0:\n",
    "        matching = pairing_result.calculated_matchings_list[0]\n",
    "        matching_pairs_count = len(matching.get_donor_recipient_pairs())\n",
    "        \n",
    "        #print(pairing_result.score_matrix)\n",
    "        #for pair in matching.get_donor_recipient_pairs():\n",
    "        #    print(f\"{pair.donor.medical_id} -> {pair.recipient.medical_id}\")\n",
    "    else:\n",
    "        matching_pairs_count = 0\n",
    "    \n",
    "    return matching_pairs_count, len(donors), len(recipients)\n",
    "\n",
    "df_donors = get_donors_for_granularity(txm_event=24, granularity=1)\n",
    "df_recipients = get_recipients_for_granularity(txm_event=24, granularity=1)\n",
    "compute_for_patients(df_donors, df_recipients)\n",
    "# display(df_donors)\n",
    "# df_recipients[df_recipients.columns[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "\n",
    "for txm_event in range(10, 31):\n",
    "    for granularity in range(1, 5):\n",
    "        #df_patients = get_patients_for_granularity(txm_event=txm_event, granularity=granularity)\n",
    "        df_donors = get_donors_for_granularity(txm_event=txm_event, granularity=granularity)\n",
    "        df_recipients = get_recipients_for_granularity(txm_event=txm_event, granularity=granularity)\n",
    "        \n",
    "        donors_count = len(df_donors.index)\n",
    "        recipients_count = len(df_recipients.index)\n",
    "        \n",
    "        print(f\"Computing matching for txm_event {txm_event} and granularity {granularity} ({donors_count} donors, {recipients_count} recipients)\", end=\" \")\n",
    "        start = time.time()\n",
    "        matching_pairs_count, valid_donors, valid_recipients = compute_for_patients(df_donors, df_recipients)\n",
    "        elapsed_time = time.time() - start\n",
    "        print(f\"-> {matching_pairs_count} transplants found ({elapsed_time:.2f} seconds)\")\n",
    "        \n",
    "        d.append({\n",
    "            'txm_event': txm_event,\n",
    "            'granularity': granularity,\n",
    "            'donors_count': donors_count,\n",
    "            'recipients_count': recipients_count,\n",
    "            'valid_donors': valid_donors,\n",
    "            'valid_recipients': valid_recipients,\n",
    "            'matching_pairs_count': matching_pairs_count,\n",
    "            'matching_pairs_count_normalized': matching_pairs_count / granularity,\n",
    "            'elapsed_time': elapsed_time\n",
    "        })\n",
    "\n",
    "df_granularity_results = pd.DataFrame(d)\n",
    "df_granularity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is computed now. Lets show some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_granularity_results.pivot_table(index='txm_event', columns='granularity', values=['donors_count']).plot(ylabel='Donors count')\n",
    "df_granularity_results.pivot_table(index='txm_event', columns='granularity', values='recipients_count').plot(ylabel='Recipients count')\n",
    "df_granularity_results.pivot_table(index='txm_event', columns='granularity', values='matching_pairs_count').plot(ylabel='matching_pairs_count')\n",
    "df_granularity_results.pivot_table(index='txm_event', columns='granularity', values='matching_pairs_count_normalized').plot(ylabel='matching_pairs_count_normalized')\n",
    "df_granularity_results.pivot_table(index='txm_event', columns='granularity', values='elapsed_time').plot(ylabel='elapsed_time (s)')\n",
    "\n",
    "for granularity in range(1, 5):\n",
    "    df_granularity_results\\\n",
    "        .loc[lambda df: df.granularity == granularity]\\\n",
    "        .set_index('txm_event')\\\n",
    "        [['donors_count', 'recipients_count', 'matching_pairs_count']]\\\n",
    "        .plot(title=f'granularity = {granularity}')\n",
    "        #.assign(ratio=lambda df: df.matching_pairs_count / df.patients_count)\\\n",
    "        #.assign(diff=lambda df: - df.matching_pairs_count + df.patients_count)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare with original transplant count\n",
    "Now, lets suppose granularity = 1 and compare the computed results with original transplant count that we know using survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transplant_counts = df_all_patients_with_survival\\\n",
    "    .groupby('txm_event')\\\n",
    "    .sum()\\\n",
    "    .assign(recipient_transplants=lambda df: df.recip_has_transplant)\\\n",
    "    .assign(donor_transplants=lambda df: df.donor_has_transplant)\\\n",
    "    [['recipient_transplants', 'donor_transplants']]\n",
    "\n",
    "# df_transplant_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_granularity_results.loc[lambda df: df.granularity == 1].set_index('txm_event')[['matching_pairs_count']]\\\n",
    "    .join(df_transplant_counts).plot(\n",
    "    title='Computed transplant count versus original transplant count from survival data',\n",
    "    style=[\"-\", \"o-\", \"-\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group by 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_per_year = df_granularity_results\\\n",
    "    .assign(year=lambda df: (df.txm_event-10)//4)\\\n",
    "    .assign(event_in_year=lambda df: (df.txm_event-10)%4)\n",
    "df_results_per_year.loc[lambda df: (df.event_in_year + 1) % df.granularity != 0, 'matching_pairs_count'] = 0\n",
    "df_results_per_year = df_results_per_year.groupby(['year', 'granularity']).sum().reset_index()\\\n",
    "    .pivot_table(index='year', columns='granularity', values='matching_pairs_count')\n",
    "\n",
    "df_results_per_year.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TXM new",
   "language": "python",
   "name": "txmatching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
